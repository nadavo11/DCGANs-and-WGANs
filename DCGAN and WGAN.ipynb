{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1eFLvQiNup5E",
    "outputId": "96aa7b03-9b84-43fe-cfe7-610237c59931",
    "ExecuteTime": {
     "end_time": "2024-07-28T11:20:21.388911Z",
     "start_time": "2024-07-28T11:20:15.121452500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "import wandb\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "FOLDER_PATH = '/content/drive/MyDrive/Deep Learning/ex3_305673212_312349509/FashionMNIST'\n",
    "if (os.path.exists(FOLDER_PATH)):\n",
    "  path = FOLDER_PATH\n",
    "else:\n",
    "  path = \"data\" #for git runs"
   ],
   "metadata": {
    "id": "JX1AAx1mu0cI",
    "ExecuteTime": {
     "end_time": "2024-07-28T11:20:21.406939800Z",
     "start_time": "2024-07-28T11:20:21.395956600Z"
    }
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#hyper parameters\n",
    "#TODO: the WGAN paper states lr= 5e-5, should we use it?\n",
    "MODE = 'wgan-gp' # dcgan, wgan, or wgan-gp\n",
    "DIM = 64 # Model dimensionality\n",
    "BATCH_SIZE = 50 # Batch size\n",
    "CRITIC_ITERS = 5 # For WGAN and WGAN-GP, number of critic iters per gen iter\n",
    "LAMBDA = 10 # Gradient penalty lambda hyperparameter\n",
    "ITERS = 200000 # How many generator iterations to train for\n",
    "OUTPUT_DIM = 784 # Number of pixels in MNIST (28*28)\n",
    "LATENT_DIM = 128\n",
    "in_channels = 1\n"
   ],
   "metadata": {
    "id": "4nZ4flZ3vM_p",
    "ExecuteTime": {
     "end_time": "2024-07-28T11:20:21.463489200Z",
     "start_time": "2024-07-28T11:20:21.408938300Z"
    }
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# W&B\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "_OJ3eVs0vSdz"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#TODO: remove before submission\n",
    "import wandb\n",
    "from mycreds import WANDB_API_KEY\n",
    "wandb.login(key=WANDB_API_KEY)\n",
    "\n"
   ],
   "metadata": {
    "id": "F1EvPz5fvZVe",
    "ExecuteTime": {
     "end_time": "2024-07-28T11:20:27.887650300Z",
     "start_time": "2024-07-28T11:20:21.426174600Z"
    }
   },
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: nadavo11 (nadavoteam). Use `wandb login --relogin` to force relogin\n",
      "wandb: WARNING If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "wandb: WARNING Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "wandb: Appending key for api.wandb.ai to your netrc file: C:\\Users\\nadav\\_netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Preprocessing\n",
    "## Data loaders\n",
    "let's prepare our data by loading it, normalizing it, and creating the data loaders."
   ],
   "metadata": {
    "id": "ASRHqmTFvgUa"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "# train_data_raw = open(f'{path}/ptb.train.txt', 'r').read()\n",
    "# test_data_raw = open(f'{path}/ptb.test.txt', 'r').read()\n",
    "# valid_data_raw = open(f'{path}/ptb.valid.txt', 'r').read()\n",
    "# data =  train_data_raw + ' ' + test_data_raw + ' ' + valid_data_raw\n",
    "#\n",
    "# # Create dataloaders\n",
    "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "# valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "#\n",
    "# test_data_iter = iter(test_loader)\n",
    "# train_data_iter = iter(train_loader)\n",
    "# valid_data_iter = iter(valid_loader)"
   ],
   "metadata": {
    "id": "fYZucckgvdgJ",
    "ExecuteTime": {
     "end_time": "2024-07-28T11:20:27.940817700Z",
     "start_time": "2024-07-28T11:20:27.891651300Z"
    }
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# TODO: can we use this for FashionMNIST instead?\n",
    "\n",
    "# Define the transform to convert the images to tensors and normalize them\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.RandomRotation((-30, 30)),\n",
    "    # transforms.RandomHorizontalFlip(),\n",
    "])\n",
    "\n",
    "# Download and load the training data\n",
    "train_dataset = datasets.FashionMNIST(root='data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.FashionMNIST(root='data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Create DataLoader for training and testing\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-28T11:20:28.072679500Z",
     "start_time": "2024-07-28T11:20:27.932702700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Network Architecture\n",
    "We will implemnet gernerator and descriminator/critic as defined in \"Improved Training of Wasserstein GANs\" papaer for CIFAR10, then we will make adjustments to be compatible to FashuionMNIST data set\n",
    "\n",
    "MNIST/ Fashion MNIST Input Dimensionsimages are 28x28 grayscale images, while CIFAR-10 images are 32x32 RGB images. We will modify the input and output layers of the networks accordingly.\n",
    "\n"
   ],
   "metadata": {
    "id": "qcFTPGZ33jiL"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# generator\n",
    "\n",
    "### conv dimensions\n",
    "convolution dimensions are calculated as follows: $ x = \\frac{W - k + 2P}{S} + 1 $ deconv dimensions are calculated as follows: $ x = S(W-1) + k - 2P + F $ where: - W is the input image size - k is the kernel size - P is the padding - S is the stride - F is the output padding\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-28T11:20:28.085093400Z",
     "start_time": "2024-07-28T11:20:28.073673900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "#Input to Generator is noise which can be random or not, nosie dimention is 128\n",
    "\n",
    "class Generator(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 dim=DIM,\n",
    "                 mode='wgan',\n",
    "                 latent_dim = LATENT_DIM):\n",
    "\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.dim = dim\n",
    "        if mode: self.mode = mode.lower()\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        # 1. Fully connected:\n",
    "        # 128 -> 4*4*4*dim\n",
    "        self.linear = nn.Linear(latent_dim,\n",
    "                                4*4*4*dim)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(4*4*4*dim)\n",
    "\n",
    "        # 2. deConv\n",
    "        # (4x4) 4dim -> (10x10) 2dim\n",
    "        self.deconv2 = nn.ConvTranspose2d(4*dim,\n",
    "                                          2*dim,\n",
    "                                          kernel_size=5,\n",
    "                                          stride=2,\n",
    "                                          padding=2,\n",
    "                                          output_padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(2*dim)\n",
    "\n",
    "        # 3. deConv\n",
    "        # (12x12) 2dim -> (24x24) dim\n",
    "        self.deconv3 = nn.ConvTranspose2d(2*dim,\n",
    "                                          dim,\n",
    "                                          kernel_size=5,\n",
    "                                          stride=2,\n",
    "                                          padding=2,\n",
    "                                          output_padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(dim)\n",
    "\n",
    "        # 4. deConv\n",
    "        #(24x24) dim -> (28x28) 3\n",
    "        self.deconv4 = nn.ConvTranspose2d(dim,\n",
    "                                          3,\n",
    "                                          kernel_size=5,\n",
    "                                          stride=1,\n",
    "                                          padding=0,\n",
    "                                          output_padding=0)\n",
    "\n",
    "\n",
    "    # TODO : complete forward function\n",
    "    #  check if we need to add noise to the forward function\n",
    "    def forward(self, n_samples, noise=None):\n",
    "        if noise is None:\n",
    "            noise = torch.randn(n_samples, self.latent_dim).to(device)\n",
    "\n",
    "        # 1. Fully connected\n",
    "        output = self.linear(noise)\n",
    "        if self.mode == 'wgan':\n",
    "            output = self.bn1(output)\n",
    "        output = F.relu(output)\n",
    "        output = output.view(-1, 4*self.dim, 4, 4)\n",
    "\n",
    "        # 2.Deconv\n",
    "        output = self.deconv2(output)\n",
    "        if self.mode == 'wgan':\n",
    "            output = self.bn2(output)\n",
    "        output = F.relu(output)\n",
    "\n",
    "        # 3. Deconv\n",
    "        output = self.deconv3(output)\n",
    "        output = self.bn3(output)\n",
    "        output = F.relu(output)\n",
    "\n",
    "        # 4. Deconv\n",
    "        output = self.deconv4(output)\n",
    "        output = torch.tanh(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "9FVOhPEW4BYM",
    "ExecuteTime": {
     "end_time": "2024-07-28T11:20:28.148482800Z",
     "start_time": "2024-07-28T11:20:28.090618800Z"
    }
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    " # Discriminator\n",
    "\n",
    "convolution dimensions are calculated as follows: $ x = \\frac{W - k + 2P}{S} + 1 $ deconv dimensions are calculated as follows: $ x = S(W-1) + k - 2P + F $ where: - W is the input image size - k is the kernel size - P is the padding - S is the stride - F is the output padding"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self,\n",
    "                dim = DIM,\n",
    "                mode = 'wgan',\n",
    "                in_channels = 3,):\n",
    "\n",
    "        super(Discriminator, self).__init__()\n",
    "        if mode:\n",
    "            self.mode = mode.lower()\n",
    "        self.conv1 = nn.Conv2d(kernel_size=5,\n",
    "                             in_channels=in_channels,\n",
    "                             out_channels=dim,\n",
    "                             stride=2,) # 12x12\n",
    "\n",
    "        self.conv2 = nn.Conv2d(kernel_size=5,\n",
    "                                in_channels=dim,\n",
    "                                out_channels=2*dim,\n",
    "                                stride=2,) # 4x4\n",
    "        # Unique to WGAN\n",
    "        self.batch_norm2 = nn.BatchNorm2d(2*dim)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(kernel_size=1,\n",
    "                                in_channels=2*dim,\n",
    "                                out_channels=4*dim,\n",
    "                                stride=1,) # 4x4\n",
    "        # Unique to WGAN\n",
    "        self.batch_norm3 = nn.BatchNorm2d(4*4*4*dim)\n",
    "\n",
    "        self.fc = nn.Linear(4*4*4*dim, 1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = F.leaky_relu(self.conv1(x), negative_slope=0.2)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "\n",
    "        if self.mode == 'wgan':\n",
    "            x = self.bn2(x)\n",
    "\n",
    "        x = F.leaky_relu(x, negative_slope=0.2)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "\n",
    "        if self.mode == 'wgan':\n",
    "            x = self.bn3(x)\n",
    "\n",
    "        x = F.leaky_relu(x, negative_slope=0.2)\n",
    "\n",
    "        x = x.view(-1, 4*4*4*self.dim)  # Flatten\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-28T11:20:28.221689100Z",
     "start_time": "2024-07-28T11:20:28.173626100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "id": "8KyqmO5D9ykZ"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "class GAN(nn.Module):\n",
    "    def __init__(self,\n",
    "                 dim=DIM,\n",
    "                 mode='wgan',\n",
    "                 latent_dim=LATENT_DIM,\n",
    "                 ):\n",
    "        super(GAN, self).__init__()\n",
    "        self.generator = Generator(dim = dim,\n",
    "                                   mode = mode,\n",
    "                                   latent_dim= latent_dim)\n",
    "        self.discriminator = Discriminator(dim = dim,\n",
    "                                           mode = mode,)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-28T11:20:28.234533300Z",
     "start_time": "2024-07-28T11:20:28.227698500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation\n",
    "we define our evaluation metric as the inception score:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-28T11:20:28.255591600Z",
     "start_time": "2024-07-28T11:20:28.236531100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# TODO: Implement inception score function\n",
    "def inception_score():\n",
    "    pass\n",
    "\n",
    "# TODO : Implement the evaluator loop\n",
    "def evaluate():\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-28T11:20:28.271444200Z",
     "start_time": "2024-07-28T11:20:28.254591800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Test the generator\n",
    "can be removed before submission"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    }
   ],
   "source": [
    "generator = Generator()\n",
    "img = generator.forward(10)\n",
    "\n",
    "\n",
    "plt.imshow(img[0].transpose(0,2).detach().numpy(), cmap='gray')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-07-28T11:20:28.272459900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Lost Function/ Inception"
   ],
   "metadata": {
    "id": "aS3sNzRv6d9j"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "class GAN:\n",
    "  def __init__(self, dim, mode, train_loader):\n",
    "    self.generator = Generator(dim)\n",
    "    self.discriminator = Discriminator(in_features, input_img_w, input_img_h, DIM, kernel_size)\n",
    "    self.mode = mode\n",
    "    self.gen_optimizer = optim.RMSprop(self.generator.parameters(), lr=5e-5)\n",
    "    self.disc_optimizer = optim.RMSprop(self.discriminator.parameters(), lr=5e-5)\n",
    "    self.setup_optimizers()\n",
    "    self.train_loader = train_loader\n",
    "\n",
    "    # NADAV/REUT: Do we need to defrenciate the optimizers?\n",
    "\n",
    "    #def setup_optimizers(self):\n",
    "    #     if self.mode == 'wgan':\n",
    "    #         self.gen_optimizer = optim.RMSprop(self.generator.parameters(), lr=5e-5)\n",
    "    #         self.disc_optimizer = optim.RMSprop(self.discriminator.parameters(), lr=5e-5)\n",
    "    #     elif self.mode == 'dcgan':\n",
    "    #         self.gen_optimizer = optim.Adam(self.generator.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
    "    #         self.disc_optimizer = optim.Adam(self.discriminator.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
    "\n",
    "    def inf_train_gen(self):\n",
    "        while True:\n",
    "            for images, _ in self.train_loader:\n",
    "                yield images\n",
    "\n",
    "    def generate_image(self, frame):\n",
    "        fixed_noise_128 = torch.randn(128, 128).to(device)\n",
    "        samples = self.generator(128, fixed_noise_128).detach().cpu().numpy()\n",
    "        samples = ((samples + 1.) * (255. / 2)).astype('int32')\n",
    "        save_image(torch.tensor(samples).view(128, 3, 32, 32), 'samples_{}.jpg'.format(frame))\n",
    "\n",
    "    def get_inception_score(self):\n",
    "        samples_100 = self.generator(100).detach().cpu().numpy()\n",
    "        all_samples = []\n",
    "        for _ in range(10):\n",
    "            all_samples.append(samples_100)\n",
    "        all_samples = np.concatenate(all_samples, axis=0)\n",
    "        all_samples = ((all_samples + 1.) * (255. / 2)).astype('int32')\n",
    "        all_samples = all_samples.reshape((-1, 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "        return lib.inception_score.get_inception_score(list(all_samples))\n",
    "\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "        for iteration in range(self.iters):\n",
    "            start_time = time.time()\n",
    "            # Train generator\n",
    "            if iteration > 0:\n",
    "                self.gen_optimizer.zero_grad()\n",
    "                fake_data = self.generator(self.batch_size)\n",
    "                disc_fake = self.discriminator(fake_data)\n",
    "                gen_cost = -torch.mean(disc_fake) if self.mode == 'wgan' else F.binary_cross_entropy_with_logits(disc_fake, torch.ones_like(disc_fake))\n",
    "                gen_cost.backward()\n",
    "                self.gen_optimizer.step()\n",
    "\n",
    "            # Train critic\n",
    "            disc_iters = 1 if self.mode == 'dcgan' else self.critic_iters\n",
    "            for _ in range(disc_iters):\n",
    "                _data = next(self.inf_train_gen()).to(device)\n",
    "                self.disc_optimizer.zero_grad()\n",
    "                disc_real = self.discriminator(_data)\n",
    "                fake_data = self.generator(self.batch_size)\n",
    "                disc_fake = self.discriminator(fake_data)\n",
    "\n",
    "                disc_cost = torch.mean(disc_fake) - torch.mean(disc_real) if self.mode == 'wgan' else \\\n",
    "                            (F.binary_cross_entropy_with_logits(disc_fake, torch.zeros_like(disc_fake)) +\n",
    "                             F.binary_cross_entropy_with_logits(disc_real, torch.ones_like(disc_real))) / 2.\n",
    "                disc_cost.backward()\n",
    "                self.disc_optimizer.step()\n",
    "\n",
    "                if self.mode == 'wgan':\n",
    "                    for p in self.discriminator.parameters():\n",
    "                        p.data.clamp_(-0.01, 0.01)\n",
    "\n",
    "            # Logging\n",
    "            print(f\"Iteration {iteration}, Disc Cost: {disc_cost.item()}, Time: {time.time() - start_time}\")\n",
    "\n",
    "            # Calculate inception score every 1K iters\n",
    "            if iteration % 1000 == 999:\n",
    "                inception_score = self.get_inception_score()\n",
    "                print(f\"Inception Score: {inception_score[0]}\")\n",
    "\n",
    "            # Generate samples every 100 iters\n",
    "            if iteration % 100 == 99:\n",
    "                self.generate_image(iteration)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "OBR51wMnVKnr",
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n"
   ],
   "metadata": {
    "id": "kKzFYyU94Oog",
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
