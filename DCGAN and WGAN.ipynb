{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1eFLvQiNup5E",
    "outputId": "96aa7b03-9b84-43fe-cfe7-610237c59931"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "from datetime import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import wandb\n",
    "\n",
    "# from torchtext.data.utils import get_tokenizer\n",
    "# from torchtext.vocab import build_vocab_from_iterator\n",
    "# import torchtext.transforms as T\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "FOLDER_PATH = '/content/drive/MyDrive/Deep Learning/ex3_305673212_312349509/FashionMNIST'\n",
    "if (os.path.exists(FOLDER_PATH)):\n",
    "  path = FOLDER_PATH\n",
    "else:\n",
    "  path = \"data\" #for git runs"
   ],
   "metadata": {
    "id": "JX1AAx1mu0cI"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#hyper parameters\n",
    "#TODO: the WGAN paper states lr= 5e-5, should we use it?\n",
    "lr = 1e-4 #as defined in improve_wgan_training github repo\n",
    "epochs = 40\n",
    "DIM = 64\n",
    "CRITIC_ITERS = 5 # How many critic iterations per generator iteration\n",
    "BATCH_SIZE = 64 # Batch size\n",
    "ITERS = 200000 # How many generator iterations to train for\n",
    "input_img_w = 28 #FashionMNIST Width\n",
    "input_img_h = 28 #FashionMNIST Hight\n",
    "in_features = 1\n",
    "latent_space = 128\n",
    "kerenel_size = 5\n",
    "OUTPUT_DIM = input_img_w*input_img_h*in_features # Number of pixels in FashionMNIST (28*28*1)\n"
   ],
   "metadata": {
    "id": "4nZ4flZ3vM_p"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# W&B\n",
    "wandb.init(project=\"ex3\", entity=\"danielshamir\")\n",
    "wandb.config.lr = lr\n",
    "wandb.config.epochs = epochs\n",
    "wandb.config.DIM = DIM\n",
    "wandb.config.CRITIC_ITERS = CRITIC_ITERS\n",
    "wandb.config.BATCH_SIZE = BATCH_SIZE\n",
    "wandb.config.ITERS = ITERS\n",
    "wandb.config.input_img_w = input_img_w\n",
    "wandb.config.input_img_h = input_img_h\n",
    "wandb.config.in_features = in_features\n",
    "wandb.config.latent_space = latent_space\n",
    "wandb.config.kerenel_size = kerenel_size\n",
    "wandb.config.OUTPUT_DIM = OUTPUT_DIM\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "_OJ3eVs0vSdz"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "! pip install wandb\n",
    "import wandb"
   ],
   "metadata": {
    "id": "F1EvPz5fvZVe",
    "ExecuteTime": {
     "end_time": "2024-07-27T19:59:54.862722200Z",
     "start_time": "2024-07-27T19:59:24.386643500Z"
    }
   },
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wandb\n",
      "  Using cached wandb-0.17.5-py3-none-win_amd64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in c:\\users\\nadav\\appdata\\roaming\\python\\python310\\site-packages (from wandb) (8.1.7)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
      "  Using cached docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb)\n",
      "  Using cached GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\nadav\\anaconda3\\envs\\dcgan and wgan\\lib\\site-packages (from wandb) (3.10.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in c:\\users\\nadav\\appdata\\roaming\\python\\python310\\site-packages (from wandb) (3.20.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in c:\\users\\nadav\\anaconda3\\envs\\dcgan and wgan\\lib\\site-packages (from wandb) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\nadav\\appdata\\roaming\\python\\python310\\site-packages (from wandb) (6.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in c:\\users\\nadav\\appdata\\roaming\\python\\python310\\site-packages (from wandb) (2.31.0)\n",
      "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
      "  Using cached sentry_sdk-2.11.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting setproctitle (from wandb)\n",
      "  Using cached setproctitle-1.3.3-cp310-cp310-win_amd64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\nadav\\anaconda3\\envs\\dcgan and wgan\\lib\\site-packages (from wandb) (69.5.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\nadav\\appdata\\roaming\\python\\python310\\site-packages (from click!=8.0.0,>=7.1->wandb) (0.4.6)\n",
      "Requirement already satisfied: six>=1.4.0 in c:\\users\\nadav\\appdata\\roaming\\python\\python310\\site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb)\n",
      "  Using cached gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nadav\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2.0.0->wandb) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nadav\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nadav\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2.0.0->wandb) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nadav\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2.0.0->wandb) (2023.7.22)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb)\n",
      "  Using cached smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Using cached wandb-0.17.5-py3-none-win_amd64.whl (6.7 MB)\n",
      "Using cached docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Using cached GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
      "Using cached sentry_sdk-2.11.0-py2.py3-none-any.whl (303 kB)\n",
      "Using cached setproctitle-1.3.3-cp310-cp310-win_amd64.whl (11 kB)\n",
      "Using cached gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "Using cached smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, gitpython, wandb\n",
      "Successfully installed docker-pycreds-0.4.0 gitdb-4.0.11 gitpython-3.1.43 sentry-sdk-2.11.0 setproctitle-1.3.3 smmap-5.0.1 wandb-0.17.5\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "h8B6fIURvbP3"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "BYq7RYdCvdEA"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Preprocessing\n",
    "Data loaders"
   ],
   "metadata": {
    "id": "ASRHqmTFvgUa"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "train_data_raw = open(f'{path}/ptb.train.txt', 'r').read()\n",
    "test_data_raw = open(f'{path}/ptb.test.txt', 'r').read()\n",
    "valid_data_raw = open(f'{path}/ptb.valid.txt', 'r').read()\n",
    "data =  train_data_raw + ' ' + test_data_raw + ' ' + valid_data_raw\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "\n",
    "test_data_iter = iter(test_loader)\n",
    "train_data_iter = iter(train_loader)\n",
    "valid_data_iter = iter(valid_loader)"
   ],
   "metadata": {
    "id": "fYZucckgvdgJ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Network Architecture\n",
    "We will implemnet gernerator and descriminator/critic as defined in \"Improved Training of Wasserstein GANs\" papaer for CIFAR10, then we will make adjustments to be compatible to FashuionMNIST data set\n",
    "\n",
    "MNIST/ Fashion MNIST Input Dimensionsimages are 28x28 grayscale images, while CIFAR-10 images are 32x32 RGB images. We will modify the input and output layers of the networks accordingly.\n",
    "\n"
   ],
   "metadata": {
    "id": "qcFTPGZ33jiL"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "#Input to Generator is noise which can be random or not, nosie dimention is 128\n",
    "\n",
    "def Generator(n_samples, noise=None):\n",
    "  def __init__(self, dim):\n",
    "    super(Generator, self).__init__()\n",
    "    self.dim = dim\n",
    "    self.linear = nn.Linear(latent_space, 4*4*4*dim)\n",
    "    self.bn1 = nn.BatchNorm1d(4*4*4*dim)\n",
    "    self.deconv2 = nn.ConvTranspose2d(4*dim, 2*dim, kernel_size=5, stride=2, padding=2, output_padding=1)\n",
    "    self.bn2 = nn.BatchNorm2d(2*dim)\n",
    "    self.deconv3 = nn.ConvTranspose2d(2*dim, dim, kernel_size=5, stride=2, padding=2, output_padding=1)\n",
    "    self.bn3 = nn.BatchNorm2d(dim)\n",
    "    self.deconv4 = nn.ConvTranspose2d(dim, 3, kernel_size=5, stride=2, padding=2, output_padding=1)\n",
    "\n",
    "\n",
    "  def forward(self, n_samples, noise=None):\n",
    "    if noise is None:\n",
    "        noise = torch.randn(n_samples, latent_space)\n",
    "\n",
    "    output = self.linear(noise)\n",
    "    output = self.bn1(output)\n",
    "    output = F.relu(output)\n",
    "    output = output.view(-1, 4*self.dim, 4, 4)\n",
    "\n",
    "    output = self.deconv2(output)\n",
    "    output = self.bn2(output)\n",
    "    output = F.relu(output)\n",
    "\n",
    "    output = self.deconv3(output)\n",
    "    output = self.bn3(output)\n",
    "    output = F.relu(output)\n",
    "\n",
    "    output = self.deconv4(output)\n",
    "    output = torch.tanh(output)\n",
    "\n",
    "    return output.view(-1, OUTPUT_DIM)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "  def __init__(self, in_features, input_img_w, input_img_h, DIM, kernel_size):\n",
    "      super(Discriminator, self).__init__()\n",
    "      self.in_features = in_features\n",
    "      self.input_img_w = input_img_w\n",
    "      self.input_img_h = input_img_h\n",
    "      self.DIM = DIM\n",
    "      self.kernel_size = kernel_size\n",
    "\n",
    "      self.conv1 = nn.Conv2d(in_features, DIM, kernel_size, stride=2)\n",
    "      self.conv2 = nn.Conv2d(DIM, 2*DIM, kernel_size, stride=2)\n",
    "      self.bn2 = nn.BatchNorm2d(2*DIM)\n",
    "      self.conv3 = nn.Conv2d(2*DIM, 4*DIM, kernel_size, stride=2)\n",
    "      self.bn3 = nn.BatchNorm2d(4*DIM)\n",
    "      self.fc = nn.Linear(4*4*4*DIM, 1)\n",
    "\n",
    "  def forward(self, inputs):\n",
    "      output = inputs.view(-1, self.in_features, self.input_img_w, self.input_img_h)\n",
    "\n",
    "      output = F.leaky_relu(self.conv1(output), negative_slope=0.2)\n",
    "\n",
    "      output = F.leaky_relu(self.bn2(self.conv2(output)), negative_slope=0.2)\n",
    "\n",
    "      output = F.leaky_relu(self.bn3(self.conv3(output)), negative_slope=0.2)\n",
    "\n",
    "      output = output.view(-1, 4*4*4*self.DIM)\n",
    "      output = self.fc(output)\n",
    "\n",
    "      return output.view(-1)\n"
   ],
   "metadata": {
    "id": "9FVOhPEW4BYM"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "id": "8KyqmO5D9ykZ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Lost Function/ Inception"
   ],
   "metadata": {
    "id": "aS3sNzRv6d9j"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "class GAN:\n",
    "  def __init__(self, dim, mode, train_loader):\n",
    "    self.generator = Generator(dim)\n",
    "    self.discriminator = Discriminator(in_features, input_img_w, input_img_h, DIM, kernel_size)\n",
    "    self.mode = mode\n",
    "    self.gen_optimizer = optim.RMSprop(self.generator.parameters(), lr=5e-5)\n",
    "    self.disc_optimizer = optim.RMSprop(self.discriminator.parameters(), lr=5e-5)\n",
    "    self.setup_optimizers()\n",
    "    self.train_loader = train_loader\n",
    "\n",
    "    # NADAV/REUT: Do we need to defrenciate the optimizers?\n",
    "\n",
    "    #def setup_optimizers(self):\n",
    "    #     if self.mode == 'wgan':\n",
    "    #         self.gen_optimizer = optim.RMSprop(self.generator.parameters(), lr=5e-5)\n",
    "    #         self.disc_optimizer = optim.RMSprop(self.discriminator.parameters(), lr=5e-5)\n",
    "    #     elif self.mode == 'dcgan':\n",
    "    #         self.gen_optimizer = optim.Adam(self.generator.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
    "    #         self.disc_optimizer = optim.Adam(self.discriminator.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
    "\n",
    "    def inf_train_gen(self):\n",
    "        while True:\n",
    "            for images, _ in self.train_loader:\n",
    "                yield images\n",
    "\n",
    "    def generate_image(self, frame):\n",
    "        fixed_noise_128 = torch.randn(128, 128).to(device)\n",
    "        samples = self.generator(128, fixed_noise_128).detach().cpu().numpy()\n",
    "        samples = ((samples + 1.) * (255. / 2)).astype('int32')\n",
    "        save_image(torch.tensor(samples).view(128, 3, 32, 32), 'samples_{}.jpg'.format(frame))\n",
    "\n",
    "    def get_inception_score(self):\n",
    "        samples_100 = self.generator(100).detach().cpu().numpy()\n",
    "        all_samples = []\n",
    "        for _ in range(10):\n",
    "            all_samples.append(samples_100)\n",
    "        all_samples = np.concatenate(all_samples, axis=0)\n",
    "        all_samples = ((all_samples + 1.) * (255. / 2)).astype('int32')\n",
    "        all_samples = all_samples.reshape((-1, 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "        return lib.inception_score.get_inception_score(list(all_samples))\n",
    "\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "        for iteration in range(self.iters):\n",
    "            start_time = time.time()\n",
    "            # Train generator\n",
    "            if iteration > 0:\n",
    "                self.gen_optimizer.zero_grad()\n",
    "                fake_data = self.generator(self.batch_size)\n",
    "                disc_fake = self.discriminator(fake_data)\n",
    "                gen_cost = -torch.mean(disc_fake) if self.mode == 'wgan' else F.binary_cross_entropy_with_logits(disc_fake, torch.ones_like(disc_fake))\n",
    "                gen_cost.backward()\n",
    "                self.gen_optimizer.step()\n",
    "\n",
    "            # Train critic\n",
    "            disc_iters = 1 if self.mode == 'dcgan' else self.critic_iters\n",
    "            for _ in range(disc_iters):\n",
    "                _data = next(self.inf_train_gen()).to(device)\n",
    "                self.disc_optimizer.zero_grad()\n",
    "                disc_real = self.discriminator(_data)\n",
    "                fake_data = self.generator(self.batch_size)\n",
    "                disc_fake = self.discriminator(fake_data)\n",
    "\n",
    "                disc_cost = torch.mean(disc_fake) - torch.mean(disc_real) if self.mode == 'wgan' else \\\n",
    "                            (F.binary_cross_entropy_with_logits(disc_fake, torch.zeros_like(disc_fake)) +\n",
    "                             F.binary_cross_entropy_with_logits(disc_real, torch.ones_like(disc_real))) / 2.\n",
    "                disc_cost.backward()\n",
    "                self.disc_optimizer.step()\n",
    "\n",
    "                if self.mode == 'wgan':\n",
    "                    for p in self.discriminator.parameters():\n",
    "                        p.data.clamp_(-0.01, 0.01)\n",
    "\n",
    "            # Logging\n",
    "            print(f\"Iteration {iteration}, Disc Cost: {disc_cost.item()}, Time: {time.time() - start_time}\")\n",
    "\n",
    "            # Calculate inception score every 1K iters\n",
    "            if iteration % 1000 == 999:\n",
    "                inception_score = self.get_inception_score()\n",
    "                print(f\"Inception Score: {inception_score[0]}\")\n",
    "\n",
    "            # Generate samples every 100 iters\n",
    "            if iteration % 100 == 99:\n",
    "                self.generate_image(iteration)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "OBR51wMnVKnr"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n"
   ],
   "metadata": {
    "id": "kKzFYyU94Oog"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
