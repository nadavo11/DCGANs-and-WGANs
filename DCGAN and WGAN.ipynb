{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T11:20:21.388911Z",
     "start_time": "2024-07-28T11:20:15.121452500Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1eFLvQiNup5E",
    "outputId": "96aa7b03-9b84-43fe-cfe7-610237c59931"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from torchvision.models import inception_v3\n",
    "from torchvision.transforms import functional as TF\n",
    "from torchvision import datasets, transforms\n",
    "from scipy.stats import entropy\n",
    "\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "#import wandb\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T11:20:21.406939800Z",
     "start_time": "2024-07-28T11:20:21.395956600Z"
    },
    "id": "JX1AAx1mu0cI"
   },
   "outputs": [],
   "source": [
    "FOLDER_PATH = '/content/drive/MyDrive/Deep Learning/ex3_305673212_312349509/FashionMNIST'\n",
    "if (os.path.exists(FOLDER_PATH)):\n",
    "  path = FOLDER_PATH\n",
    "else:\n",
    "  path = \"data\" #for git runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T11:20:21.463489200Z",
     "start_time": "2024-07-28T11:20:21.408938300Z"
    },
    "id": "4nZ4flZ3vM_p"
   },
   "outputs": [],
   "source": [
    "#hyper parameters\n",
    "#TODO: the WGAN paper states lr= 5e-5, should we use it?\n",
    "DIM = 64 # Model dimensionality\n",
    "BATCH_SIZE = 50 # Batch size\n",
    "CRITIC_ITERS = 5 # For WGAN and WGAN-GP, number of critic iters per gen iter\n",
    "LAMBDA = 10 # Gradient penalty lambda hyperparameter\n",
    "GEN_ITERS = 200000 # How many generator iterations to train for\n",
    "LATENT_DIM = 128\n",
    "in_channels = 1\n",
    "input_img_w = 28 #FashionMNIST Width\n",
    "input_img_h = 28 #FashionMNIST Hight\n",
    "OUTPUT_DIM = input_img_w*input_img_h # Number of pixels in MNIST (28*28)\n",
    "CIFAR_SIZE = (32,32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_OJ3eVs0vSdz"
   },
   "source": [
    "# W&B\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T11:20:27.887650300Z",
     "start_time": "2024-07-28T11:20:21.426174600Z"
    },
    "id": "F1EvPz5fvZVe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: nadavo11 (nadavoteam). Use `wandb login --relogin` to force relogin\n",
      "wandb: WARNING If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "wandb: WARNING Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "wandb: Appending key for api.wandb.ai to your netrc file: C:\\Users\\nadav\\_netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO: remove before submission\n",
    "import wandb\n",
    "from mycreds import WANDB_API_KEY\n",
    "wandb.login(key=WANDB_API_KEY)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ASRHqmTFvgUa"
   },
   "source": [
    "# Data Preprocessing\n",
    "## Data loaders\n",
    "let's prepare our data by loading it, normalizing it, and creating the data loaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T11:20:28.072679500Z",
     "start_time": "2024-07-28T11:20:27.932702700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\n",
    "# Define the transform to convert the images to tensors and normalize them and resize them to 32X32 to match CIFAR input\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(CIFAR_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "# Download and load the training data\n",
    "train_dataset = datasets.FashionMNIST(root=path, train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.FashionMNIST(root=path, train=False, download=True, transform=transform)\n",
    "\n",
    "# Create DataLoader for training and testing\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "train_iter = iter(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qcFTPGZ33jiL"
   },
   "source": [
    "# Network Architecture\n",
    "We will implemnet gernerator and descriminator/critic as defined in \"Improved Training of Wasserstein GANs\" papaer for CIFAR10We decided to resize the FashionMNIST images from 28X28X1 to 32X32X1 to be able to use same conv layers used in the paper\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# generator\n",
    "\n",
    "### conv dimensions\n",
    "convolution dimensions are calculated as follows: $ x = \\frac{W - k + 2P}{S} + 1 $ deconv dimensions are calculated as follows: $ x = S(W-1) + k - 2P + F $ where: - W is the input image size - k is the kernel size - P is the padding - S is the stride - F is the output padding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T11:20:28.085093400Z",
     "start_time": "2024-07-28T11:20:28.073673900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T11:20:28.148482800Z",
     "start_time": "2024-07-28T11:20:28.090618800Z"
    },
    "id": "9FVOhPEW4BYM"
   },
   "outputs": [],
   "source": [
    "\n",
    "#Input to Generator is noise which can be random or not, nosie dimention is 128\n",
    "\n",
    "class Generator(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 dim=DIM,\n",
    "                 latent_dim = LATENT_DIM):\n",
    "\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.dim = dim\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        # 1. Fully connected:\n",
    "        # 128 -> 4*4*4*dim\n",
    "        self.linear = nn.Linear(latent_dim,\n",
    "                                4*4*4*dim)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(4*4*4*dim)\n",
    "\n",
    "        # 2. deConv\n",
    "        # (4x4) 4dim -> (8x8) 2dim\n",
    "        self.deconv2 = nn.ConvTranspose2d(4*dim,\n",
    "                                          2*dim,\n",
    "                                          kernel_size=5,\n",
    "                                          stride=2,\n",
    "                                          padding=2,\n",
    "                                          output_padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(2*dim)\n",
    "\n",
    "        # 3. deConv\n",
    "        # (8x8) 2dim -> (16x16) dim\n",
    "        self.deconv3 = nn.ConvTranspose2d(2*dim,\n",
    "                                          dim,\n",
    "                                          kernel_size=5,\n",
    "                                          stride=2,\n",
    "                                          padding=2,\n",
    "                                          output_padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(dim)\n",
    "\n",
    "        # 4. deConv\n",
    "        #(16x16) dim -> (32X32) 1\n",
    "        self.deconv4 = nn.ConvTranspose2d(dim,\n",
    "                                          in_channels,\n",
    "                                          kernel_size=5,\n",
    "                                          stride=2,\n",
    "                                          padding=2,\n",
    "                                          output_padding=1)\n",
    "\n",
    "\n",
    "    # TODO : complete forward function\n",
    "    #  check if we need to add noise to the forward function\n",
    "    def forward(self, n_samples, noise=None):\n",
    "        if noise is None:\n",
    "            noise = torch.randn(n_samples, self.latent_dim).to(device)\n",
    "\n",
    "        # 1. Fully connected\n",
    "        output = self.linear(noise)\n",
    "        output = self.bn1(output)\n",
    "        output = F.relu(output)\n",
    "        output = output.view(-1, 4*self.dim, 4, 4)\n",
    "\n",
    "        # 2.Deconv\n",
    "        output = self.deconv2(output)\n",
    "        output = self.bn2(output)\n",
    "        output = F.relu(output)\n",
    "\n",
    "        # 3. Deconv\n",
    "        output = self.deconv3(output)\n",
    "        output = self.bn3(output)\n",
    "        output = F.relu(output)\n",
    "\n",
    "        # 4. Deconv\n",
    "        output = self.deconv4(output)\n",
    "        output = torch.tanh(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    " # Discriminator\n",
    "\n",
    "convolution dimensions are calculated as follows: $ x = \\frac{W - k + 2P}{S} + 1 $ deconv dimensions are calculated as follows: $ x = S(W-1) + k - 2P + F $ where: - W is the input image size - k is the kernel size - P is the padding - S is the stride - F is the output padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T11:20:28.221689100Z",
     "start_time": "2024-07-28T11:20:28.173626100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self,\n",
    "                dim = DIM,\n",
    "                in_channels = 1):\n",
    "\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.in_features = in_channels\n",
    "        self.dim=dim\n",
    "        self.conv1 = nn.Conv2d(kernel_size=5,\n",
    "                             in_channels=in_channels,\n",
    "                             out_channels=self.dim,\n",
    "                             stride=2,) # dimX14X4\n",
    "\n",
    "        self.conv2 = nn.Conv2d(kernel_size=5,\n",
    "                                in_channels=self.dim,\n",
    "                                out_channels=2*self.dim,\n",
    "                                stride=2,) # 2dimX5X5\n",
    "        self.batch_norm2 = nn.BatchNorm2d(2*self.dim)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(kernel_size=1,\n",
    "                                in_channels=2*self.dim,\n",
    "                                out_channels=4*self.dim,\n",
    "                                stride=1,) # 4dimX5X5\n",
    "        self.batch_norm3 = nn.BatchNorm2d(4*self.dim)\n",
    "\n",
    "        self.fc = nn.Linear(4*5*5*self.dim, 1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.conv1(x), negative_slope=0.2)\n",
    "        x = self.conv2(x)\n",
    "        x = self.batch_norm2(x)\n",
    "        x = F.leaky_relu(x, negative_slope=0.2)\n",
    "        x = self.conv3(x)\n",
    "        x = self.batch_norm3(x)\n",
    "        x = F.leaky_relu(x, negative_slope=0.2)\n",
    "        x = x.view(-1, 4*5*5*self.dim)  # Flatten\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8KyqmO5D9ykZ"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T11:20:28.234533300Z",
     "start_time": "2024-07-28T11:20:28.227698500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class GAN(nn.Module):\n",
    "    def __init__(self,\n",
    "                 dim=DIM,\n",
    "                 mode='wgan',\n",
    "                 latent_dim=LATENT_DIM,\n",
    "                 ):\n",
    "        super(GAN, self).__init__()\n",
    "        self.generator = Generator(dim = dim,\n",
    "                                   mode = mode,\n",
    "                                   latent_dim= latent_dim)\n",
    "        self.discriminator = Discriminator(dim = dim,\n",
    "                                           mode = mode,in_channels=in_channels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Evaluation\n",
    "we define our evaluation metric as the inception score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T11:20:28.271444200Z",
     "start_time": "2024-07-28T11:20:28.254591800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Inception score (Evaluation)\n",
    "def inception_score(images, batch_size=32, splits=10):\n",
    "    # Load pre-trained InceptionV3 model\n",
    "    inception_model = inception_v3(pretrained=True, transform_input=False).eval()\n",
    "    \n",
    "    def get_pred(x):\n",
    "        with torch.no_grad():\n",
    "            x = inception_model(x)\n",
    "        return F.softmax(x, dim=1).cpu().numpy()\n",
    "    \n",
    "    # Resize images to 299x299 as required by InceptionV3\n",
    "    images = [TF.resize(img, (299, 299)) for img in images]\n",
    "    images = torch.stack(images)\n",
    "    \n",
    "    # Calculate predictions\n",
    "    preds = []\n",
    "    for i in range(0, len(images), batch_size):\n",
    "        batch = images[i:i + batch_size]\n",
    "        preds.append(get_pred(batch))\n",
    "    preds = np.concatenate(preds, axis=0)\n",
    "    \n",
    "    # Calculate Inception Score\n",
    "    split_scores = []\n",
    "    for k in range(splits):\n",
    "        part = preds[k * (len(preds) // splits): (k + 1) * (len(preds) // splits), :]\n",
    "        py = np.mean(part, axis=0)\n",
    "        scores = []\n",
    "        for i in range(part.shape[0]):\n",
    "            pyx = part[i, :]\n",
    "            scores.append(entropy(pyx, py))\n",
    "        split_scores.append(np.exp(np.mean(scores)))\n",
    "    \n",
    "    return np.mean(split_scores), np.std(split_scores)\n",
    "\n",
    "def disc_cost (mode,disc_fake,disc_real):\n",
    "    return (torch.mean(disc_fake) - torch.mean(disc_real) if mode == 'wgan' else \\\n",
    "                            (F.binary_cross_entropy_with_logits(disc_fake, torch.zeros_like(disc_fake)) +\n",
    "                                F.binary_cross_entropy_with_logits(disc_real, torch.ones_like(disc_real))) / 2.)\n",
    "\n",
    "def gen_cost(disc_fake,mode):\n",
    "    return (-torch.mean(disc_fake) if mode == 'wgan' else F.binary_cross_entropy_with_logits(disc_fake, torch.ones_like(disc_fake)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Test the generator\n",
    "can be removed before submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-07-28T11:20:28.272459900Z"
    },
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generator = Generator()\n",
    "img = generator.forward(15)\n",
    "\n",
    "\n",
    "plt.imshow(img[0].transpose(0,2).detach().numpy(), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aS3sNzRv6d9j"
   },
   "source": [
    "#Lost Function/ Inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "id": "OBR51wMnVKnr",
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class GAN:\n",
    "    def __init__(self, generator, discriminator, mode, train_loader, val_loader, gen_iters, critic_iters, batch_size = BATCH_SIZE):\n",
    "        self.generator = generator \n",
    "        self.discriminator = discriminator \n",
    "        self.mode = mode\n",
    "        self.gen_optimizer = optim.RMSprop(self.generator.parameters(), lr=5e-5)\n",
    "        self.disc_optimizer = optim.RMSprop(self.discriminator.parameters(), lr=5e-5)\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.gen_iters =gen_iters\n",
    "        self.critic_iters = critic_iters\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    # NADAV/REUT: Do we need to defrenciate the optimizers?\n",
    " #   self.setup_optimizers()\n",
    "\n",
    "    #def setup_optimizers(self):\n",
    "    #     if self.mode == 'wgan':\n",
    "    #         self.gen_optimizer = optim.RMSprop(self.generator.parameters(), lr=5e-5)\n",
    "    #         self.disc_optimizer = optim.RMSprop(self.discriminator.parameters(), lr=5e-5)\n",
    "    #     elif self.mode == 'dcgan':\n",
    "    #         self.gen_optimizer = optim.Adam(self.generator.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
    "    #         self.disc_optimizer = optim.Adam(self.discriminator.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
    "\n",
    "  #TODO: Consider change it if training is too heavey \n",
    "    def inf_train_gen(self):\n",
    "        while True:\n",
    "            for images, _ in self.train_loader:\n",
    "                yield images\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "        for iteration in range(self.gen_iters):\n",
    "            start_time = time.time()\n",
    "            # Train generator\n",
    "            self.gen_optimizer.zero_grad()\n",
    "            fake_data = self.generator(self.batch_size)\n",
    "            disc_fake = self.discriminator(fake_data)\n",
    "            gen_cost_val = gen_cost(mode=self.mode,disc_fake=disc_fake )\n",
    "            gen_cost_val.backward()\n",
    "            self.gen_optimizer.step()\n",
    "\n",
    "            # Train critic/dicriminator\n",
    "            disc_iters = 1 if self.mode == 'dcgan' else self.critic_iters\n",
    "            for _ in range(disc_iters):\n",
    "                _data = next(self.inf_train_gen()).to(device)\n",
    "                self.disc_optimizer.zero_grad()\n",
    "                disc_real = self.discriminator(_data)\n",
    "                fake_data = self.generator(self.batch_size)\n",
    "                disc_fake = self.discriminator(fake_data)\n",
    "\n",
    "                disc_cost_val =disc_cost(mode=self.mode,disc_real=disc_real,disc_fake=disc_fake) \n",
    "                disc_cost_val.backward()\n",
    "                self.disc_optimizer.step()\n",
    "\n",
    "                if self.mode == 'wgan':\n",
    "                    for p in self.discriminator.parameters():\n",
    "                        p.data.clamp_(-0.01, 0.01)\n",
    "                        \n",
    "            print(f\"Iteration {iteration}, Generator Cost: {gen_cost_val}, Discriminator Cost: {disc_cost_val} Time: {time.time() - start_time}\")\n",
    "\n",
    "            # Logging\n",
    "\n",
    "            # Calculate inception score every 1K iters\n",
    "            if iteration % 1000 == 999:\n",
    "                with torch.no_grad():\n",
    "                    z = torch.randn(1000, 100, 1, 1).to(device)\n",
    "                    generated_imgs = generator(z)\n",
    "                    generated_imgs = generated_imgs.cpu()\n",
    "                    inception_mean, inception_std = inception_score(generated_imgs)\n",
    "                    print(f\"Genrator Iteration {iteration}: Inception Score: {inception_mean} Â± {inception_std}\")\n",
    "                    img = generator.forward(10)\n",
    "                    plt.imshow(img[0].transpose(0,2).detach().numpy(), cmap='gray')\n",
    "                    plt.show()\n",
    "\n",
    "            # Calculate val loss of the discriminator and generate samples every 100 iters\n",
    "            if iteration % 100 == 99:\n",
    "                val_disc_costs = []\n",
    "                for images, _ in self.val_loader:\n",
    "                    images = torch.tensor(images).float()  # Convert images to a PyTorch tensor\n",
    "                    fake_data = self.generator(self.batch_size)\n",
    "                    disc_fake = self.discriminator(fake_data)\n",
    "                    _dev_disc_cost = disc_cost(mode=self.mode,disc_real=images,disc_fake=disc_fake)  # Compute the discriminator cost\n",
    "                    val_disc_costs.append(_dev_disc_cost.item())  # Append the cost to the list\n",
    "                mean_dev_disc_cost = np.mean(val_disc_costs) #TODO plot\n",
    "\n",
    "    \n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "id": "kKzFYyU94Oog",
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Generator Cost: 0.7348595261573792, Discriminator Cost: 1.1095303297042847 Time: 1.6824288368225098\n",
      "Iteration 1, Generator Cost: 2.6257317066192627, Discriminator Cost: 0.6569658517837524 Time: 0.3909926414489746\n",
      "Iteration 2, Generator Cost: 2.3675899505615234, Discriminator Cost: 0.7768301963806152 Time: 0.37479066848754883\n",
      "Iteration 3, Generator Cost: 2.268214464187622, Discriminator Cost: 0.5312726497650146 Time: 0.3556523323059082\n",
      "Iteration 4, Generator Cost: 2.2292985916137695, Discriminator Cost: 0.5633546113967896 Time: 0.6164097785949707\n",
      "Iteration 5, Generator Cost: 1.9984145164489746, Discriminator Cost: 0.543925940990448 Time: 0.9483444690704346\n",
      "Iteration 6, Generator Cost: 1.8418936729431152, Discriminator Cost: 0.5731967091560364 Time: 0.38655805587768555\n",
      "Iteration 7, Generator Cost: 1.748278021812439, Discriminator Cost: 0.5034918785095215 Time: 0.3570435047149658\n",
      "Iteration 8, Generator Cost: 1.7690112590789795, Discriminator Cost: 0.645229160785675 Time: 0.36316752433776855\n",
      "Iteration 9, Generator Cost: 1.5792737007141113, Discriminator Cost: 0.572944164276123 Time: 0.36652398109436035\n",
      "Iteration 10, Generator Cost: 1.6188113689422607, Discriminator Cost: 0.45362305641174316 Time: 0.42214131355285645\n",
      "Iteration 11, Generator Cost: 1.5635333061218262, Discriminator Cost: 0.47959548234939575 Time: 0.36971330642700195\n",
      "Iteration 12, Generator Cost: 1.6665054559707642, Discriminator Cost: 0.3727596402168274 Time: 0.3746342658996582\n",
      "Iteration 13, Generator Cost: 1.7172393798828125, Discriminator Cost: 0.3590872585773468 Time: 0.3236515522003174\n",
      "Iteration 14, Generator Cost: 1.8130934238433838, Discriminator Cost: 0.35510265827178955 Time: 0.40899133682250977\n",
      "Iteration 15, Generator Cost: 1.7495367527008057, Discriminator Cost: 0.3421390652656555 Time: 0.3431575298309326\n",
      "Iteration 16, Generator Cost: 1.8251413106918335, Discriminator Cost: 0.348389595746994 Time: 0.3571782112121582\n",
      "Iteration 17, Generator Cost: 1.9001975059509277, Discriminator Cost: 0.29481977224349976 Time: 0.3549058437347412\n",
      "Iteration 18, Generator Cost: 1.9211715459823608, Discriminator Cost: 0.31816810369491577 Time: 0.3470449447631836\n",
      "Iteration 19, Generator Cost: 1.7269537448883057, Discriminator Cost: 0.40376800298690796 Time: 0.3334817886352539\n",
      "Iteration 20, Generator Cost: 1.5971572399139404, Discriminator Cost: 0.49140465259552 Time: 0.35691332817077637\n",
      "Iteration 21, Generator Cost: 1.547224998474121, Discriminator Cost: 0.4712061882019043 Time: 0.3503916263580322\n",
      "Iteration 22, Generator Cost: 1.4919230937957764, Discriminator Cost: 0.431990385055542 Time: 0.3363454341888428\n",
      "Iteration 23, Generator Cost: 1.5637398958206177, Discriminator Cost: 0.40411221981048584 Time: 0.35398173332214355\n",
      "Iteration 24, Generator Cost: 1.6850342750549316, Discriminator Cost: 0.35483527183532715 Time: 0.3262302875518799\n",
      "Iteration 25, Generator Cost: 1.8041906356811523, Discriminator Cost: 0.39424800872802734 Time: 0.34471678733825684\n",
      "Iteration 26, Generator Cost: 1.6778620481491089, Discriminator Cost: 0.382424533367157 Time: 0.3458676338195801\n",
      "Iteration 27, Generator Cost: 1.753106713294983, Discriminator Cost: 0.37275832891464233 Time: 0.3553915023803711\n",
      "Iteration 28, Generator Cost: 1.7804648876190186, Discriminator Cost: 0.3531939685344696 Time: 0.34756040573120117\n",
      "Iteration 29, Generator Cost: 1.7506526708602905, Discriminator Cost: 0.3511853814125061 Time: 0.3469815254211426\n",
      "Iteration 30, Generator Cost: 1.6709707975387573, Discriminator Cost: 0.3431128263473511 Time: 0.3473212718963623\n",
      "Iteration 31, Generator Cost: 1.7754243612289429, Discriminator Cost: 0.33406922221183777 Time: 0.36064767837524414\n",
      "Iteration 32, Generator Cost: 1.707491159439087, Discriminator Cost: 0.3212102949619293 Time: 0.3585975170135498\n",
      "Iteration 33, Generator Cost: 1.7089126110076904, Discriminator Cost: 0.33052146434783936 Time: 0.3603098392486572\n",
      "Iteration 34, Generator Cost: 1.6575032472610474, Discriminator Cost: 0.31815457344055176 Time: 0.34503889083862305\n",
      "Iteration 35, Generator Cost: 1.6815009117126465, Discriminator Cost: 0.28522276878356934 Time: 0.3571937084197998\n",
      "Iteration 36, Generator Cost: 1.7575998306274414, Discriminator Cost: 0.3420245051383972 Time: 0.3462357521057129\n",
      "Iteration 37, Generator Cost: 1.700769066810608, Discriminator Cost: 0.34281039237976074 Time: 0.3632090091705322\n",
      "Iteration 38, Generator Cost: 1.7069741487503052, Discriminator Cost: 0.2986486554145813 Time: 0.3501002788543701\n",
      "Iteration 39, Generator Cost: 1.7847720384597778, Discriminator Cost: 0.285592257976532 Time: 0.3504645824432373\n",
      "Iteration 40, Generator Cost: 1.8604555130004883, Discriminator Cost: 0.28480520844459534 Time: 0.3422057628631592\n",
      "Iteration 41, Generator Cost: 1.8630470037460327, Discriminator Cost: 0.27449437975883484 Time: 0.347564697265625\n",
      "Iteration 42, Generator Cost: 1.927796483039856, Discriminator Cost: 0.22617360949516296 Time: 0.3597588539123535\n",
      "Iteration 43, Generator Cost: 2.010896921157837, Discriminator Cost: 0.24678730964660645 Time: 0.3464925289154053\n",
      "Iteration 44, Generator Cost: 2.0368130207061768, Discriminator Cost: 0.23663175106048584 Time: 0.3378007411956787\n",
      "Iteration 45, Generator Cost: 2.0878419876098633, Discriminator Cost: 0.2147883027791977 Time: 0.3474240303039551\n",
      "Iteration 46, Generator Cost: 2.0453131198883057, Discriminator Cost: 0.287339985370636 Time: 0.34087300300598145\n",
      "Iteration 47, Generator Cost: 1.9444341659545898, Discriminator Cost: 0.2401627004146576 Time: 0.34723496437072754\n",
      "Iteration 48, Generator Cost: 2.0177855491638184, Discriminator Cost: 0.2362971305847168 Time: 0.3522379398345947\n",
      "Iteration 49, Generator Cost: 2.057880401611328, Discriminator Cost: 0.2625071704387665 Time: 0.3373250961303711\n",
      "Iteration 50, Generator Cost: 1.9750304222106934, Discriminator Cost: 0.23160475492477417 Time: 0.3419976234436035\n",
      "Iteration 51, Generator Cost: 2.0364294052124023, Discriminator Cost: 0.33863842487335205 Time: 0.34575986862182617\n",
      "Iteration 52, Generator Cost: 1.895024061203003, Discriminator Cost: 0.2607988715171814 Time: 0.35397768020629883\n",
      "Iteration 53, Generator Cost: 1.8750147819519043, Discriminator Cost: 0.2767156660556793 Time: 0.34994006156921387\n",
      "Iteration 54, Generator Cost: 1.9667346477508545, Discriminator Cost: 0.2410537600517273 Time: 0.34462571144104004\n",
      "Iteration 55, Generator Cost: 2.0165719985961914, Discriminator Cost: 0.2212287187576294 Time: 0.34594011306762695\n",
      "Iteration 56, Generator Cost: 2.1011056900024414, Discriminator Cost: 0.27140986919403076 Time: 0.34837770462036133\n",
      "Iteration 57, Generator Cost: 2.0933005809783936, Discriminator Cost: 0.21973156929016113 Time: 0.33494067192077637\n",
      "Iteration 58, Generator Cost: 2.1523895263671875, Discriminator Cost: 0.24493658542633057 Time: 0.35402870178222656\n",
      "Iteration 59, Generator Cost: 2.041048765182495, Discriminator Cost: 0.22325871884822845 Time: 0.333815336227417\n",
      "Iteration 60, Generator Cost: 2.020721673965454, Discriminator Cost: 0.29628491401672363 Time: 0.3460667133331299\n",
      "Iteration 61, Generator Cost: 2.014836072921753, Discriminator Cost: 0.2203790247440338 Time: 0.34780335426330566\n",
      "Iteration 62, Generator Cost: 2.072355031967163, Discriminator Cost: 0.2607254087924957 Time: 0.3439512252807617\n",
      "Iteration 63, Generator Cost: 2.1276280879974365, Discriminator Cost: 0.22112545371055603 Time: 0.34525251388549805\n",
      "Iteration 64, Generator Cost: 2.0312752723693848, Discriminator Cost: 0.2633400559425354 Time: 0.352583646774292\n",
      "Iteration 65, Generator Cost: 2.0146422386169434, Discriminator Cost: 0.26078033447265625 Time: 0.33606863021850586\n",
      "Iteration 66, Generator Cost: 2.081695795059204, Discriminator Cost: 0.21781137585639954 Time: 0.3453199863433838\n",
      "Iteration 67, Generator Cost: 2.185786724090576, Discriminator Cost: 0.21322456002235413 Time: 0.3451347351074219\n",
      "Iteration 68, Generator Cost: 2.1149191856384277, Discriminator Cost: 0.2180231809616089 Time: 0.3507845401763916\n",
      "Iteration 69, Generator Cost: 2.1575493812561035, Discriminator Cost: 0.20750442147254944 Time: 0.35733461380004883\n",
      "Iteration 70, Generator Cost: 2.1862475872039795, Discriminator Cost: 0.1726851761341095 Time: 0.3381338119506836\n",
      "Iteration 71, Generator Cost: 2.3561675548553467, Discriminator Cost: 0.2067655324935913 Time: 0.34458255767822266\n",
      "Iteration 72, Generator Cost: 2.421971082687378, Discriminator Cost: 0.1848272681236267 Time: 0.3435986042022705\n",
      "Iteration 73, Generator Cost: 2.449586868286133, Discriminator Cost: 0.141396164894104 Time: 0.3358919620513916\n",
      "Iteration 74, Generator Cost: 2.4919633865356445, Discriminator Cost: 0.15417928993701935 Time: 0.35399675369262695\n",
      "Iteration 75, Generator Cost: 2.4676103591918945, Discriminator Cost: 0.1359662115573883 Time: 0.3388214111328125\n",
      "Iteration 76, Generator Cost: 2.4959616661071777, Discriminator Cost: 0.16068431735038757 Time: 0.3390054702758789\n",
      "Iteration 77, Generator Cost: 2.4914608001708984, Discriminator Cost: 0.16078436374664307 Time: 0.3400452136993408\n",
      "Iteration 78, Generator Cost: 2.5526413917541504, Discriminator Cost: 0.1401539146900177 Time: 0.3432121276855469\n",
      "Iteration 79, Generator Cost: 2.5759637355804443, Discriminator Cost: 0.12859266996383667 Time: 0.346118688583374\n",
      "Iteration 80, Generator Cost: 2.7134714126586914, Discriminator Cost: 0.10704804211854935 Time: 0.3476676940917969\n",
      "Iteration 81, Generator Cost: 2.7339465618133545, Discriminator Cost: 0.14431944489479065 Time: 0.35244321823120117\n",
      "Iteration 82, Generator Cost: 2.598641872406006, Discriminator Cost: 0.14339220523834229 Time: 0.3338003158569336\n",
      "Iteration 83, Generator Cost: 2.559297800064087, Discriminator Cost: 0.1344452202320099 Time: 0.3460545539855957\n",
      "Iteration 84, Generator Cost: 2.592667579650879, Discriminator Cost: 0.14330267906188965 Time: 0.35463643074035645\n",
      "Iteration 85, Generator Cost: 2.6651549339294434, Discriminator Cost: 0.14149123430252075 Time: 0.3329288959503174\n",
      "Iteration 86, Generator Cost: 2.6536989212036133, Discriminator Cost: 0.13331520557403564 Time: 0.3430759906768799\n",
      "Iteration 87, Generator Cost: 2.7479352951049805, Discriminator Cost: 0.13627423346042633 Time: 0.3278493881225586\n",
      "Iteration 88, Generator Cost: 2.789485216140747, Discriminator Cost: 0.10642224550247192 Time: 0.337801456451416\n",
      "Iteration 89, Generator Cost: 2.738034725189209, Discriminator Cost: 0.12043551355600357 Time: 0.3371748924255371\n",
      "Iteration 90, Generator Cost: 2.7631871700286865, Discriminator Cost: 0.15399610996246338 Time: 0.3291451930999756\n",
      "Iteration 91, Generator Cost: 2.6989405155181885, Discriminator Cost: 0.11534366011619568 Time: 0.34929537773132324\n",
      "Iteration 92, Generator Cost: 2.7676751613616943, Discriminator Cost: 0.14820238947868347 Time: 0.33911776542663574\n",
      "Iteration 93, Generator Cost: 2.809356689453125, Discriminator Cost: 0.1357889324426651 Time: 0.3478736877441406\n",
      "Iteration 94, Generator Cost: 2.8151814937591553, Discriminator Cost: 0.1172085776925087 Time: 0.3369312286376953\n",
      "Iteration 95, Generator Cost: 2.735926628112793, Discriminator Cost: 0.1898338794708252 Time: 0.3452908992767334\n",
      "Iteration 96, Generator Cost: 2.534566640853882, Discriminator Cost: 0.19455479085445404 Time: 0.34672045707702637\n",
      "Iteration 97, Generator Cost: 2.3999767303466797, Discriminator Cost: 0.18336613476276398 Time: 0.3561215400695801\n",
      "Iteration 98, Generator Cost: 2.488502264022827, Discriminator Cost: 0.19056198000907898 Time: 0.36282777786254883\n",
      "Iteration 99, Generator Cost: 2.444676399230957, Discriminator Cost: 0.1607109159231186 Time: 0.3472590446472168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\reuts\\AppData\\Local\\Temp\\ipykernel_24184\\1325811456.py:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  images = torch.tensor(images).float()  # Convert images to a PyTorch tensor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 100, Generator Cost: 2.555795669555664, Discriminator Cost: 0.15564575791358948 Time: 0.390796422958374\n",
      "Iteration 101, Generator Cost: 2.6103811264038086, Discriminator Cost: 0.12265787273645401 Time: 0.410494327545166\n",
      "Iteration 102, Generator Cost: 2.605031967163086, Discriminator Cost: 0.1384369432926178 Time: 0.41831326484680176\n",
      "Iteration 103, Generator Cost: 2.6453566551208496, Discriminator Cost: 0.14243890345096588 Time: 0.36763620376586914\n",
      "Iteration 104, Generator Cost: 2.6144869327545166, Discriminator Cost: 0.1835012137889862 Time: 0.4323148727416992\n",
      "Iteration 105, Generator Cost: 2.593388557434082, Discriminator Cost: 0.1481555998325348 Time: 0.45316219329833984\n",
      "Iteration 106, Generator Cost: 2.6421616077423096, Discriminator Cost: 0.13692985475063324 Time: 0.4575684070587158\n",
      "Iteration 107, Generator Cost: 2.555687189102173, Discriminator Cost: 0.16948093473911285 Time: 0.39868664741516113\n",
      "Iteration 108, Generator Cost: 2.6335549354553223, Discriminator Cost: 0.1638353317975998 Time: 0.47463226318359375\n",
      "Iteration 109, Generator Cost: 2.5873186588287354, Discriminator Cost: 0.14400431513786316 Time: 0.39098477363586426\n",
      "Iteration 110, Generator Cost: 2.643167018890381, Discriminator Cost: 0.12640340626239777 Time: 0.39434051513671875\n",
      "Iteration 111, Generator Cost: 2.731665849685669, Discriminator Cost: 0.12819810211658478 Time: 0.5104091167449951\n",
      "Iteration 112, Generator Cost: 2.70098876953125, Discriminator Cost: 0.13781581819057465 Time: 0.38625574111938477\n",
      "Iteration 113, Generator Cost: 2.637385845184326, Discriminator Cost: 0.14046651124954224 Time: 0.3751645088195801\n",
      "Iteration 114, Generator Cost: 2.7214789390563965, Discriminator Cost: 0.10679016262292862 Time: 0.3898031711578369\n",
      "Iteration 115, Generator Cost: 2.782175064086914, Discriminator Cost: 0.12282298505306244 Time: 0.36403918266296387\n",
      "Iteration 116, Generator Cost: 2.7241809368133545, Discriminator Cost: 0.13642698526382446 Time: 1.439237356185913\n",
      "Iteration 117, Generator Cost: 2.6635444164276123, Discriminator Cost: 0.1807577759027481 Time: 0.6210551261901855\n",
      "Iteration 118, Generator Cost: 2.5629520416259766, Discriminator Cost: 0.1698760986328125 Time: 0.42109060287475586\n",
      "Iteration 119, Generator Cost: 2.5661487579345703, Discriminator Cost: 0.13492222130298615 Time: 0.4275662899017334\n",
      "Iteration 120, Generator Cost: 2.6664319038391113, Discriminator Cost: 0.1365361511707306 Time: 0.37641167640686035\n",
      "Iteration 121, Generator Cost: 2.763395071029663, Discriminator Cost: 0.1241995096206665 Time: 0.5903315544128418\n",
      "Iteration 122, Generator Cost: 2.8655152320861816, Discriminator Cost: 0.1195206493139267 Time: 1.0658440589904785\n",
      "Iteration 123, Generator Cost: 2.746250629425049, Discriminator Cost: 0.13246595859527588 Time: 0.3642096519470215\n",
      "Iteration 124, Generator Cost: 2.6686313152313232, Discriminator Cost: 0.11995847523212433 Time: 0.34622812271118164\n",
      "Iteration 125, Generator Cost: 2.5738470554351807, Discriminator Cost: 0.1416938453912735 Time: 0.3458895683288574\n",
      "Iteration 126, Generator Cost: 2.6626510620117188, Discriminator Cost: 0.15056157112121582 Time: 0.38993000984191895\n",
      "Iteration 127, Generator Cost: 2.6076488494873047, Discriminator Cost: 0.17213183641433716 Time: 0.39009690284729004\n",
      "Iteration 128, Generator Cost: 2.533764600753784, Discriminator Cost: 0.15262852609157562 Time: 0.3452918529510498\n",
      "Iteration 129, Generator Cost: 2.5433168411254883, Discriminator Cost: 0.17003154754638672 Time: 0.36445116996765137\n",
      "Iteration 130, Generator Cost: 2.622091770172119, Discriminator Cost: 0.14150342345237732 Time: 0.3563234806060791\n",
      "Iteration 131, Generator Cost: 2.672837257385254, Discriminator Cost: 0.12111686170101166 Time: 0.40403008460998535\n",
      "Iteration 132, Generator Cost: 2.608273506164551, Discriminator Cost: 0.1471269726753235 Time: 0.9114329814910889\n",
      "Iteration 133, Generator Cost: 2.657289981842041, Discriminator Cost: 0.13138927519321442 Time: 0.69439697265625\n",
      "Iteration 134, Generator Cost: 2.6743357181549072, Discriminator Cost: 0.15207532048225403 Time: 0.37804198265075684\n",
      "Iteration 135, Generator Cost: 2.572007179260254, Discriminator Cost: 0.11340084671974182 Time: 0.35522007942199707\n",
      "Iteration 136, Generator Cost: 2.6326918601989746, Discriminator Cost: 0.11940089613199234 Time: 0.33727312088012695\n",
      "Iteration 137, Generator Cost: 2.723203182220459, Discriminator Cost: 0.10241193324327469 Time: 0.5142993927001953\n",
      "Iteration 138, Generator Cost: 2.8017542362213135, Discriminator Cost: 0.11114194989204407 Time: 0.35631251335144043\n",
      "Iteration 139, Generator Cost: 2.848050594329834, Discriminator Cost: 0.10868846625089645 Time: 0.3522517681121826\n",
      "Iteration 140, Generator Cost: 2.8338961601257324, Discriminator Cost: 0.11014451086521149 Time: 0.35660481452941895\n",
      "Iteration 141, Generator Cost: 2.8790531158447266, Discriminator Cost: 0.09162703156471252 Time: 0.3455827236175537\n",
      "Iteration 142, Generator Cost: 2.9897072315216064, Discriminator Cost: 0.08900398761034012 Time: 0.37978100776672363\n",
      "Iteration 143, Generator Cost: 2.9463579654693604, Discriminator Cost: 0.10437445342540741 Time: 0.5775535106658936\n",
      "Iteration 144, Generator Cost: 2.9109139442443848, Discriminator Cost: 0.09876938164234161 Time: 0.3890540599822998\n",
      "Iteration 145, Generator Cost: 2.9299304485321045, Discriminator Cost: 0.10057242214679718 Time: 0.429506778717041\n",
      "Iteration 146, Generator Cost: 2.9536924362182617, Discriminator Cost: 0.09571346640586853 Time: 0.34717750549316406\n",
      "Iteration 147, Generator Cost: 3.038088321685791, Discriminator Cost: 0.08341682702302933 Time: 0.3560633659362793\n",
      "Iteration 148, Generator Cost: 3.1094751358032227, Discriminator Cost: 0.08183421939611435 Time: 0.3508591651916504\n",
      "Iteration 149, Generator Cost: 2.9727797508239746, Discriminator Cost: 0.09780944138765335 Time: 0.3613142967224121\n",
      "Iteration 150, Generator Cost: 2.870603084564209, Discriminator Cost: 0.08808881044387817 Time: 0.3494534492492676\n",
      "Iteration 151, Generator Cost: 2.874901056289673, Discriminator Cost: 0.08622102439403534 Time: 0.3361659049987793\n",
      "Iteration 152, Generator Cost: 3.01328182220459, Discriminator Cost: 0.061335690319538116 Time: 0.33335065841674805\n",
      "Iteration 153, Generator Cost: 3.0960254669189453, Discriminator Cost: 0.08518964052200317 Time: 0.3363800048828125\n",
      "Iteration 154, Generator Cost: 3.05460262298584, Discriminator Cost: 0.08963046967983246 Time: 0.34476661682128906\n",
      "Iteration 155, Generator Cost: 3.062002182006836, Discriminator Cost: 0.08319444209337234 Time: 0.3361701965332031\n",
      "Iteration 156, Generator Cost: 3.106290340423584, Discriminator Cost: 0.08897773176431656 Time: 0.345761775970459\n",
      "Iteration 157, Generator Cost: 3.1464059352874756, Discriminator Cost: 0.09978920221328735 Time: 0.3369436264038086\n",
      "Iteration 158, Generator Cost: 3.268536329269409, Discriminator Cost: 0.07626350224018097 Time: 0.3373119831085205\n",
      "Iteration 159, Generator Cost: 3.240281105041504, Discriminator Cost: 0.08044944703578949 Time: 0.34934091567993164\n",
      "Iteration 160, Generator Cost: 3.253765344619751, Discriminator Cost: 0.05827997624874115 Time: 0.3515357971191406\n",
      "Iteration 161, Generator Cost: 3.22074556350708, Discriminator Cost: 0.08310229331254959 Time: 0.3322114944458008\n",
      "Iteration 162, Generator Cost: 3.231757164001465, Discriminator Cost: 0.06888361275196075 Time: 0.3473227024078369\n",
      "Iteration 163, Generator Cost: 3.1618812084198, Discriminator Cost: 0.0699709802865982 Time: 0.34445786476135254\n",
      "Iteration 164, Generator Cost: 3.220160484313965, Discriminator Cost: 0.09400119632482529 Time: 0.3398919105529785\n",
      "Iteration 165, Generator Cost: 3.287339448928833, Discriminator Cost: 0.07257311046123505 Time: 0.32822704315185547\n",
      "Iteration 166, Generator Cost: 3.2742509841918945, Discriminator Cost: 0.060783203691244125 Time: 0.3337247371673584\n",
      "Iteration 167, Generator Cost: 3.2562415599823, Discriminator Cost: 0.05294957011938095 Time: 0.3455684185028076\n",
      "Iteration 168, Generator Cost: 3.2954483032226562, Discriminator Cost: 0.08350876718759537 Time: 0.3253445625305176\n",
      "Iteration 169, Generator Cost: 3.2716972827911377, Discriminator Cost: 0.05150508135557175 Time: 0.32924628257751465\n",
      "Iteration 170, Generator Cost: 3.266035795211792, Discriminator Cost: 0.08069179207086563 Time: 0.34525060653686523\n",
      "Iteration 171, Generator Cost: 3.168783664703369, Discriminator Cost: 0.06757879257202148 Time: 0.33875560760498047\n",
      "Iteration 172, Generator Cost: 3.2346885204315186, Discriminator Cost: 0.05944446101784706 Time: 0.3744933605194092\n",
      "Iteration 173, Generator Cost: 3.334494113922119, Discriminator Cost: 0.05245385318994522 Time: 0.3420858383178711\n",
      "Iteration 174, Generator Cost: 3.385849714279175, Discriminator Cost: 0.08077842742204666 Time: 0.32863831520080566\n",
      "Iteration 175, Generator Cost: 3.295489549636841, Discriminator Cost: 0.06379996985197067 Time: 0.3333127498626709\n",
      "Iteration 176, Generator Cost: 3.325529098510742, Discriminator Cost: 0.05428381264209747 Time: 0.34632229804992676\n",
      "Iteration 177, Generator Cost: 3.2798047065734863, Discriminator Cost: 0.059381090104579926 Time: 0.3315887451171875\n",
      "Iteration 178, Generator Cost: 3.3128726482391357, Discriminator Cost: 0.053278662264347076 Time: 0.3838069438934326\n",
      "Iteration 179, Generator Cost: 3.3564422130584717, Discriminator Cost: 0.052254170179367065 Time: 0.32793402671813965\n",
      "Iteration 180, Generator Cost: 3.3580095767974854, Discriminator Cost: 0.06054377555847168 Time: 0.33130693435668945\n",
      "Iteration 181, Generator Cost: 3.3556289672851562, Discriminator Cost: 0.07097148895263672 Time: 0.34579014778137207\n",
      "Iteration 182, Generator Cost: 3.131486177444458, Discriminator Cost: 0.07655530422925949 Time: 0.3394787311553955\n",
      "Iteration 183, Generator Cost: 3.2470290660858154, Discriminator Cost: 0.06923215091228485 Time: 0.3638906478881836\n",
      "Iteration 184, Generator Cost: 3.2669260501861572, Discriminator Cost: 0.053696438670158386 Time: 0.34613823890686035\n",
      "Iteration 185, Generator Cost: 3.289093255996704, Discriminator Cost: 0.056904472410678864 Time: 0.34476709365844727\n",
      "Iteration 186, Generator Cost: 3.3036577701568604, Discriminator Cost: 0.058961495757102966 Time: 0.37381696701049805\n",
      "Iteration 187, Generator Cost: 3.324052333831787, Discriminator Cost: 0.06184052675962448 Time: 0.33219361305236816\n",
      "Iteration 188, Generator Cost: 3.368278741836548, Discriminator Cost: 0.04689933732151985 Time: 0.3457448482513428\n",
      "Iteration 189, Generator Cost: 3.311897039413452, Discriminator Cost: 0.053201884031295776 Time: 0.33379197120666504\n",
      "Iteration 190, Generator Cost: 3.319049596786499, Discriminator Cost: 0.06553873419761658 Time: 0.324462890625\n",
      "Iteration 191, Generator Cost: 3.398297071456909, Discriminator Cost: 0.060310423374176025 Time: 0.3397819995880127\n",
      "Iteration 192, Generator Cost: 3.352752447128296, Discriminator Cost: 0.07060369849205017 Time: 0.32559657096862793\n",
      "Iteration 193, Generator Cost: 3.3634209632873535, Discriminator Cost: 0.056471750140190125 Time: 0.3332397937774658\n",
      "Iteration 194, Generator Cost: 3.3545713424682617, Discriminator Cost: 0.04962646961212158 Time: 0.3275644779205322\n",
      "Iteration 195, Generator Cost: 3.388962984085083, Discriminator Cost: 0.045144692063331604 Time: 0.3421440124511719\n",
      "Iteration 196, Generator Cost: 3.465536594390869, Discriminator Cost: 0.04703066498041153 Time: 0.3281691074371338\n",
      "Iteration 197, Generator Cost: 3.4424526691436768, Discriminator Cost: 0.07020008563995361 Time: 0.3285176753997803\n",
      "Iteration 198, Generator Cost: 3.36203670501709, Discriminator Cost: 0.04719145596027374 Time: 0.34644651412963867\n",
      "Iteration 199, Generator Cost: 3.5273609161376953, Discriminator Cost: 0.047347985208034515 Time: 0.33382225036621094\n"
     ]
    }
   ],
   "source": [
    "dc_gen=Generator(dim = DIM,latent_dim= LATENT_DIM)\n",
    "dc_disc = Discriminator(dim = DIM,in_channels=in_channels)\n",
    "dcgan = GAN(mode = 'dcgan'\n",
    "            , train_loader=train_loader\n",
    "            , gen_iters = GEN_ITERS\n",
    "            , critic_iters=CRITIC_ITERS\n",
    "            ,batch_size = BATCH_SIZE\n",
    "            ,discriminator = dc_disc\n",
    "            ,generator = dc_gen\n",
    "            ,val_loader=test_loader)\n",
    "dcgan.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
